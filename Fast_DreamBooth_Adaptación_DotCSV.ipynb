{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vmjaramillo1/stable_diffusion_presonal_train/blob/main/Fast_DreamBooth_Adaptaci%C3%B3n_DotCSV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3GhhZmvhfxS"
      },
      "source": [
        "#‚≠ê **DreamBooth colab From https://github.com/TheLastBen/fast-stable-diffusion**\n",
        "###üõ†Ô∏è Notebook adaptado por [@dotcsv](https://www.youtube.com/channel/UCy5znSnfMsDwaLlROnZ7Qbg). Actualizado a Python 3.8 por [@Deus;Gate](https://www.youtube.com/channel/UCNojH61Q5RcbBWSLW1UjTkw)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¥ ESTE NOTEBOOK **EST√Å TEMPORALMENTE FUERA DE SERVICIO** üî¥\n",
        "\n",
        "Pr√≥ximamente volver√° a funcionar. Mientras tanto, cualquiera de las siguientes alternativas podr√≠an servir para el entrenamiento de **Dreambooth** (*versi√≥n original usada en el tutorial*) o **LoRA** (*versi√≥n m√°s ligera*)."
      ],
      "metadata": {
        "id": "98K5ng_MVXLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Notebook Name | Description | Link |\n",
        "| --- | --- | --- |\n",
        "| [Kohya LoRA Dreambooth](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb) | LoRA Training (Dreambooth method) | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=for-the-badge)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb) |\n",
        "| [Kohya LoRA Fine-Tuning](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-finetuner.ipynb) | LoRA Training (Fine-tune method) | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=for-the-badge)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-finetuner.ipynb) |\n",
        "| [Kohya Trainer](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-trainer.ipynb) | Native Training | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=for-the-badge)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-trainer.ipynb) |\n",
        "| [Kohya Dreambooth](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-dreambooth.ipynb) | Dreambooth Training | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=for-the-badge)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-dreambooth.ipynb) |"
      ],
      "metadata": {
        "id": "RGGcB2K2VTBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üö® Ten activada la **Aceleraci√≥n por hardware** con GPU en `\"Entorno de ejecuci√≥n\" > \"Cambiar tipo de entorno de ejecuci√≥n\"`"
      ],
      "metadata": {
        "id": "f-BcD0b8hwdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "cUUnmQGHm3a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b24d91fb-b7b3-4d27-9577-9d7a4df4eed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-a11feed7-c321-6344-4776-2ee7dde337e0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 1** - Conectamos con Google Drive. **Importante contar con unos 4GB de almacenamiento.**"
      ],
      "metadata": {
        "id": "WCgtpGr6ZOyG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4Bae3VP6UsE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbKbx185zqlz"
      },
      "source": [
        "### **Paso 2** - Instalamos las librer√≠as necesarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyvcqeiL65Tj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # Dependencies\n",
        "\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "\n",
        "print('\u001b[1;32mInstalling dependencies...')\n",
        "with capture.capture_output() as cap:\n",
        "    %cd /content/\n",
        "    !pip install -q --no-deps accelerate==0.12.0\n",
        "    !wget -q -i https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dependencies/db.txt\n",
        "    !dpkg -i *.deb\n",
        "    !tar -C / --zstd -xf db_deps.tar.zst\n",
        "    !rm *.deb | rm *.zst | rm *.txt\n",
        "    !git clone --depth 1 --branch updt https://github.com/TheLastBen/diffusers\n",
        "\n",
        "print('\u001b[1;32mDone, proceed')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 3** - Descargamos el modelo .ckpt de Stable Diffusion original.\n",
        "\n",
        "\n",
        "```\n",
        "üî¥ ¬°UPDATE! Ya no es necesario introducir tu token de Hugging Face üòä\n",
        "```"
      ],
      "metadata": {
        "id": "CnBAZ4eje2Sl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAY8R-EMn9Zb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import wget\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown <b>Elige el modelo a utilizar:</b> \n",
        "\n",
        "#@markdown Ahora puedes usar la t√©cnica de DreamBooth incluso en versiones m√°s actualizadas de Stable Diffusion: La versi√≥n 1.5 te ofrece un estilo m√°s art√≠stico (<i>es la utilizada en el tutorial de Youtube</i>). Y las versiones 2.1 servir√°n como una mejor base para obtener im√°genes m√°s fotorrealistas.\n",
        "\n",
        "#@markdown üöß <i>Temporalmente el soporte a la v2.1 estar√° deshabilitado. üöß\n",
        "\n",
        "Model_Version = \"1.5\" #@param [ \"1.5\"]\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd /content/\n",
        "\n",
        "if os.path.exists('/content/gdrive/MyDrive/Fast-Dreambooth/token.txt'):\n",
        "  with open(\"/content/gdrive/MyDrive/Fast-Dreambooth/token.txt\") as f:\n",
        "     token = f.read()\n",
        "  authe=f'https://USER:{token}@'\n",
        "else:\n",
        "  authe=\"https://\"\n",
        "\n",
        "def downloadmodel():\n",
        "\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5\n",
        "  clear_output()\n",
        "\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v1-5\n",
        "  %cd /content/stable-diffusion-v1-5\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "    !git clone \"https://huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "    !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "    !rm -r /content/stable-diffusion-v1-5/.git\n",
        "    %cd /content/stable-diffusion-v1-5\n",
        "    !rm model_index.json\n",
        "    time.sleep(1)    \n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
        "    !sed -i 's@\"clip_sample\": false@@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "    !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "    !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /content/stable-diffusion-v1-5/vae/config.json  \n",
        "    %cd /content/\n",
        "    clear_output()\n",
        "    print('\u001b[1;32mDONE !')\n",
        "  else:\n",
        "    while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "         print('\u001b[1;31mSomething went wrong')\n",
        "         time.sleep(5)\n",
        "\n",
        "def newdownloadmodel():\n",
        "\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v2-768\n",
        "  %cd /content/stable-diffusion-v2-768\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  !rm -r /content/stable-diffusion-v2-768/.git\n",
        "  clear_output()\n",
        "  print('\u001b[1;32mDONE !')\n",
        "\n",
        "\n",
        "def newdownloadmodelb():\n",
        "\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v2-512\n",
        "  %cd /content/stable-diffusion-v2-512\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  !rm -r /content/stable-diffusion-v2-512/.git\n",
        "  clear_output()\n",
        "  print('\u001b[1;32mDONE !')\n",
        "\n",
        "\n",
        "if Model_Version==\"1.5\":\n",
        "  if not os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    downloadmodel()\n",
        "    MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "  else:\n",
        "    MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "    print(\"\u001b[1;32mThe v1.5 model already exists, using this model.\")\n",
        "elif Model_Version==\"V2.1-512px\":\n",
        "  if not os.path.exists('/content/stable-diffusion-v2-512'):\n",
        "    newdownloadmodelb()\n",
        "    MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n",
        "  else:\n",
        "    MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n",
        "    print(\"\u001b[1;32mThe v2-512px model already exists, using this model.\")\n",
        "elif Model_Version==\"V2.1-768px\":\n",
        "  if not os.path.exists('/content/stable-diffusion-v2-768'):\n",
        "    newdownloadmodel()\n",
        "    MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n",
        "  else:\n",
        "    MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n",
        "    print(\"\u001b[1;32mThe v2-768px model already exists, using this model.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 4** - Configuramos el entrenamiento de Dreambooth."
      ],
      "metadata": {
        "id": "Wsp71Ctje5qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wget\n",
        "import time\n",
        "import shutil\n",
        "import ipywidgets as widgets\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from os import listdir\n",
        "from os.path import isfile\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from io import BytesIO\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "\n",
        "#@markdown ---\n",
        "Training_Subject = \"Character\" #@param [\"Character\", \"Object\", \"Style\", \"Artist\", \"Movie\", \"TV Show\"] \n",
        "\n",
        "With_Prior_Preservation = \"Yes\" #@param [\"Yes\", \"No\"] \n",
        "#@markdown - With the prior reservation method, the results are better, you will either have to upload around 200 pictures of the class you're training (dog, person, car, house ...) or let Dreambooth generate them.\n",
        "\n",
        "MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "SUBJECT_TYPE = \"person\" #@param{type: 'string'}\n",
        "while SUBJECT_TYPE==\"\":\n",
        "   SUBJECT_TYPE=input('Input the subject type:')\n",
        "\n",
        "#@markdown - If you're training on a character or an object, the subject type would be : Man, Woman, Shirt, Car, Dog, Baby ...etc\n",
        "#@markdown - If you're training on a Style, the subject type would be : impressionist, brutalist, abstract, use \"beautiful\" for a general style...etc\n",
        "#@markdown - If you're training on a Movie/Show, the subject type would be : Action, Drama, Science-fiction, Comedy ...etc\n",
        "#@markdown - If you're training on an Artist, the subject type would be : Painting, sketch, drawing, photography, art ...etc\n",
        "\n",
        "INSTANCE_NAME= \"tu_token_especial\" #@param{type: 'string'}\n",
        "while INSTANCE_NAME==\"\":\n",
        "   INSTANCE_NAME=input('Input the instance name (identifier) :')\n",
        "\n",
        "#@markdown - The instance is an identifier, choose a unique identifier unknown by stable diffusion. \n",
        "\n",
        "INSTANCE_DIR_OPTIONAL=\"\" #@param{type: 'string'}\n",
        "INSTANCE_DIR=INSTANCE_DIR_OPTIONAL\n",
        "while INSTANCE_DIR_OPTIONAL!=\"\" and not os.path.exists(str(INSTANCE_DIR)):\n",
        "    INSTANCE_DIR=input('\u001b[1;31mThe instance folder specified does not exist, use the colab file explorer to copy the path :')\n",
        "\n",
        "#@markdown - If the number of instance pictures is large, it is preferable to specify directly the folder instead of uploading, leave EMPTY to upload.\n",
        "\n",
        "CLASS_DIR=\"/content/data/\"+ SUBJECT_TYPE\n",
        "Number_of_subject_images=500#@param{type: 'number'}\n",
        "while Number_of_subject_images==None:\n",
        "     Number_of_subject_images=input('Input the number of subject images :')\n",
        "SUBJECT_IMAGES=Number_of_subject_images\n",
        "\n",
        "Save_class_images_to_gdrive = False #@param {type:\"boolean\"}\n",
        "#@markdown - Save time in case you're training multiple instances of the same class\n",
        "\n",
        "if Training_Subject==\"Character\" or Training_Subject==\"Object\":\n",
        "  PT=\"photo of \"+INSTANCE_NAME+\" \"+SUBJECT_TYPE\n",
        "  CPT=\"a photo of a \"+SUBJECT_TYPE+\", ultra detailed\"\n",
        "  \n",
        "OUTPUT_DIR=\"/content/models/\"+ INSTANCE_NAME\n",
        "\n",
        "if INSTANCE_DIR_OPTIONAL==\"\":\n",
        "  INSTANCE_DIR=\"/content/data/\"+INSTANCE_NAME\n",
        "  !mkdir -p \"$INSTANCE_DIR\"\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    shutil.move(filename, INSTANCE_DIR)\n",
        "    clear_output()\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "   %cd \"$INSTANCE_DIR\"\n",
        "   !find . -name \"* *\" -type f | rename 's/ /_/g'\n",
        "   %cd /content\n",
        "print('\u001b[1;32mOK')\n",
        "\n",
        "try:\n",
        "  MODEL_NAME\n",
        "  pass\n",
        "except:\n",
        "  MODEL_NAME=\"\"\n",
        "  \n",
        "PT=SUBJECT_TYPE\n",
        "\n",
        "Session_Name = INSTANCE_NAME\n",
        "\n",
        "WORKSPACE='/content/gdrive/MyDrive/Fast-Dreambooth'\n",
        "\n",
        "Session_Link_optional = \"\" # Not used\n",
        "\n",
        "INSTANCE_NAME=Session_Name\n",
        "OUTPUT_DIR=\"/content/models/\"+Session_Name\n",
        "SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n",
        "INSTANCE_DIR=SESSION_DIR+'/instance_images'\n",
        "CONCEPT_DIR=SESSION_DIR+'/concept_images'\n",
        "CAPTIONS_DIR=SESSION_DIR+'/captions'\n",
        "MDLPTH=str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n",
        "\n",
        "%cd /content"
      ],
      "metadata": {
        "cellView": "form",
        "id": "P2wiStyAHOEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 5** - (Opcional) Descargamos im√°genes de regularizaci√≥n.  üíñ Gracias [Joe Penna](https://github.com/JoePenna/Dreambooth-Stable-Diffusion)!"
      ],
      "metadata": {
        "id": "rYmyuQctfATh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown We‚Äôve created the following image sets\n",
        "#@markdown - `man_euler` - provided by Niko Pueringer (Corridor Digital) - euler @ 40 steps, CFG 7.5\n",
        "#@markdown - `man_unsplash` - pictures from various photographers\n",
        "#@markdown - `person_ddim`\n",
        "#@markdown - `woman_ddim` - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0 <br />\n",
        "#@markdown - `blonde_woman` - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0 <br />\n",
        "\n",
        "dataset=\"person_ddim\" #@param [\"man_euler\", \"man_unsplash\", \"person_ddim\", \"woman_ddim\", \"blonde_woman\"]\n",
        "!git clone https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-{dataset}.git\n",
        "\n",
        "if not os.path.exists(str(CONCEPT_DIR)):\n",
        "  %mkdir -p \"$CONCEPT_DIR\"\n",
        "\n",
        "%mkdir -p regularization_images/{dataset}\n",
        "%mv -v Stable-Diffusion-Regularization-Images-{dataset}/{dataset}/*.* \"$CONCEPT_DIR\"\n",
        "CLASS_DIR=CONCEPT_DIR"
      ],
      "metadata": {
        "id": "ze4P8wWPjy7F",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 6** - ...y ahora **¬°A ENTRENAR!** üí™"
      ],
      "metadata": {
        "id": "OmIz45s0gH5c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-9QbkfAVYYU",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "#@markdown #Start DreamBooth\n",
        "#@markdown ---\n",
        "import os\n",
        "from subprocess import getoutput\n",
        "from IPython.display import clear_output\n",
        "from google.colab import runtime\n",
        "import time\n",
        "import random\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "def rename_images(src_dir, dest_dir, token):\n",
        "    # Eliminar contenido del directorio de destino\n",
        "    for file_name in os.listdir(dest_dir):\n",
        "        file_path = os.path.join(dest_dir, file_name)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.unlink(file_path)\n",
        "        except Exception as e:\n",
        "            print(f'Error al eliminar {file_name} en {dest_dir}. Error: {e}')\n",
        "            return\n",
        "    \n",
        "    # Obtener todos los archivos de imagen en el directorio de origen\n",
        "    src_files = [f for f in os.listdir(src_dir) if f.endswith(('.jpg', '.jpeg', '.png', '.gif'))]\n",
        "    \n",
        "    # Crear el directorio de destino si no existe\n",
        "    if not os.path.exists(dest_dir):\n",
        "        os.makedirs(dest_dir)\n",
        "    \n",
        "    # Recorrer todos los archivos de imagen y renombrarlos\n",
        "    for i, src_file in enumerate(src_files):\n",
        "        # Construir el nuevo nombre del archivo\n",
        "        if i == 0:\n",
        "            new_name = f'{token}.{src_file.split(\".\")[-1]}'\n",
        "        else:\n",
        "            new_name = f'{token}-({i}).{src_file.split(\".\")[-1]}'\n",
        "        \n",
        "        # Construir las rutas completas\n",
        "        src_path = os.path.join(src_dir, src_file)\n",
        "        dest_path = os.path.join(dest_dir, new_name)\n",
        "                \n",
        "        # Renombrar y mover el archivo\n",
        "        shutil.copy2(src_path, dest_path)\n",
        "\n",
        "\n",
        "if not os.path.exists(INSTANCE_DIR):\n",
        "    # Crear el directorio si no existe\n",
        "    os.makedirs(INSTANCE_DIR)    \n",
        "\n",
        "if not os.path.exists(CAPTIONS_DIR):\n",
        "    # Crear el directorio si no existe\n",
        "    os.makedirs(CAPTIONS_DIR)\n",
        "\n",
        "rename_images(\"/content/data/\" + INSTANCE_NAME, INSTANCE_DIR, INSTANCE_NAME)\n",
        "\n",
        "if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "if os.path.exists(CONCEPT_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $CONCEPT_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "if os.path.exists(CAPTIONS_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $CAPTIONS_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "if os.path.exists(CAPTIONS_DIR+\"off\"):\n",
        "  !mv $CAPTIONS_DIR\"off\" $CAPTIONS_DIR\n",
        "\n",
        "MODELT_NAME=MODEL_NAME\n",
        "\n",
        "UNet_Training_Steps=3000 #@param{type: 'number'}\n",
        "UNet_Learning_Rate = 5e-6 #@param [\"2e-5\",\"1e-5\",\"9e-6\",\"8e-6\",\"7e-6\",\"6e-6\",\"5e-6\", \"4e-6\", \"3e-6\", \"2e-6\"] {type:\"raw\"}\n",
        "untlr=UNet_Learning_Rate\n",
        "\n",
        "Text_Encoder_Training_Steps=250\n",
        "\n",
        "Text_Encoder_Concept_Training_Steps=0\n",
        "\n",
        "Text_Encoder_Learning_Rate = 1e-6\n",
        "txlr=Text_Encoder_Learning_Rate\n",
        "\n",
        "trnonltxt=\"\"\n",
        "if UNet_Training_Steps==0:\n",
        "   trnonltxt=\"--train_only_text_encoder\"\n",
        "\n",
        "Seed=''\n",
        "\n",
        "External_Captions = False\n",
        "\n",
        "extrnlcptn=\"\"\n",
        "if External_Captions:\n",
        "  extrnlcptn=\"--external_captions\"\n",
        "\n",
        "\n",
        "Style_Training = False\n",
        "\n",
        "Style=\"\"\n",
        "if Style_Training:\n",
        "  Style=\"--Style\"\n",
        "\n",
        "Resolution = \"512\"\n",
        "Res=int(Resolution)\n",
        "\n",
        "fp16 = True\n",
        "\n",
        "if Seed =='' or Seed=='0':\n",
        "  Seed=random.randint(1, 999999)\n",
        "else:\n",
        "  Seed=int(Seed)\n",
        "\n",
        "GC=\"--gradient_checkpointing\"\n",
        "\n",
        "if fp16:\n",
        "  prec=\"fp16\"\n",
        "else:\n",
        "  prec=\"no\"\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'A100' in s:\n",
        "  GC=\"\"\n",
        "\n",
        "precision=prec\n",
        "\n",
        "resuming=\"\"\n",
        "\n",
        "Enable_text_encoder_training= True\n",
        "Enable_Text_Encoder_Concept_Training= True\n",
        "\n",
        "if Text_Encoder_Training_Steps==0 or External_Captions:\n",
        "   Enable_text_encoder_training= False\n",
        "else:\n",
        "  stptxt=Text_Encoder_Training_Steps\n",
        "\n",
        "if Text_Encoder_Concept_Training_Steps==0:\n",
        "   Enable_Text_Encoder_Concept_Training= False\n",
        "else:\n",
        "  stptxtc=Text_Encoder_Concept_Training_Steps\n",
        "\n",
        "Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
        "Save_Checkpoint_Every=500\n",
        "if Save_Checkpoint_Every==None:\n",
        "  Save_Checkpoint_Every=1\n",
        "\n",
        "stp=0\n",
        "Start_saving_from_the_step=500\n",
        "if Start_saving_from_the_step==None:\n",
        "  Start_saving_from_the_step=0\n",
        "if (Start_saving_from_the_step < 200):\n",
        "  Start_saving_from_the_step=Save_Checkpoint_Every\n",
        "stpsv=Start_saving_from_the_step\n",
        "if Save_Checkpoint_Every_n_Steps:\n",
        "  stp=Save_Checkpoint_Every\n",
        "#@markdown - Start saving intermediary checkpoints from this step.\n",
        "\n",
        "Disconnect_after_training=False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown - Auto-disconnect from google colab after the training to avoid wasting compute units.\n",
        "\n",
        "def dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
        "    \n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $trnonltxt \\\n",
        "    --image_captions_filename \\\n",
        "    --train_text_encoder \\\n",
        "    --dump_only_text_encoder \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=512 \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 $GC \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$txlr \\\n",
        "    --lr_scheduler=\"linear\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "def train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps):\n",
        "    clear_output()\n",
        "    if resuming==\"Yes\":\n",
        "      print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "    print('\u001b[1;33mTraining the UNet...\u001b[0m')\n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $Style \\\n",
        "    $extrnlcptn \\\n",
        "    --stop_text_encoder_training=$Text_Encoder_Training_Steps \\\n",
        "    --image_captions_filename \\\n",
        "    --train_only_unet \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --Session_dir=$SESSION_DIR \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$Res \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 $GC \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$untlr \\\n",
        "    --lr_scheduler=\"linear\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "\n",
        "if Enable_text_encoder_training :\n",
        "  print('\u001b[1;33mTraining the text encoder...\u001b[0m')\n",
        "  if os.path.exists(OUTPUT_DIR+'/'+'text_encoder_trained'):\n",
        "    %rm -r $OUTPUT_DIR\"/text_encoder_trained\"\n",
        "  dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n",
        "\n",
        "if Enable_Text_Encoder_Concept_Training:\n",
        "  if os.path.exists(CONCEPT_DIR):\n",
        "    if os.listdir(CONCEPT_DIR)!=[]:\n",
        "      clear_output()\n",
        "      if resuming==\"Yes\":\n",
        "        print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "      print('\u001b[1;33mTraining the text encoder on the concept...\u001b[0m')\n",
        "      dump_only_textenc(trnonltxt, MODELT_NAME, CONCEPT_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxtc)\n",
        "    else:\n",
        "      clear_output()\n",
        "      if resuming==\"Yes\":\n",
        "        print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "      print('\u001b[1;31mNo concept images found, skipping concept training...')\n",
        "      Text_Encoder_Concept_Training_Steps=0\n",
        "      time.sleep(8)\n",
        "  else:\n",
        "      clear_output()\n",
        "      if resuming==\"Yes\":\n",
        "        print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "      print('\u001b[1;31mNo concept images found, skipping concept training...')\n",
        "      Text_Encoder_Concept_Training_Steps=0\n",
        "      time.sleep(8)\n",
        "\n",
        "if UNet_Training_Steps!=0:\n",
        "  train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps=UNet_Training_Steps)\n",
        "\n",
        "if UNet_Training_Steps==0 and Text_Encoder_Concept_Training_Steps==0 and External_Captions :\n",
        "  print('\u001b[1;32mNothing to do')\n",
        "else:\n",
        "  if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "    prc=\"--fp16\" if precision==\"fp16\" else \"\"\n",
        "    !python /content/diffusers/scripts/convertosdv2.py $prc $OUTPUT_DIR $SESSION_DIR/$Session_Name\".ckpt\"\n",
        "    clear_output()\n",
        "    if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "      clear_output()\n",
        "      print(\"\u001b[1;32mDONE, the CKPT model is in your Gdrive in the sessions folder\")\n",
        "      if Disconnect_after_training :\n",
        "        time.sleep(20)\n",
        "        runtime.unassign()\n",
        "    else:\n",
        "      print(\"\u001b[1;31mSomething went wrong\")\n",
        "  else:\n",
        "    print(\"\u001b[1;31mSomething went wrong\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Paso 7** (Opcional) - **Prueba el modelo**\n"
      ],
      "metadata": {
        "id": "Qbclw_Gmg3DC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import sys\n",
        "import fileinput\n",
        "from IPython.display import clear_output\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "\n",
        "#@markdown <h3> ‚¨ÖÔ∏è ¬°Ejec√∫tame y suerte! ü§û </h3> \n",
        "\n",
        "\n",
        "Model_Version = \"1.5\"\n",
        "Previous_Session=\"\"\n",
        "\n",
        "Use_Custom_Path = False\n",
        "\n",
        "try:\n",
        "  INSTANCE_NAME\n",
        "  INSTANCET=INSTANCE_NAME\n",
        "except:\n",
        "  pass\n",
        "\n",
        "if Previous_Session!=\"\":\n",
        "  INSTANCET=Previous_Session\n",
        "  INSTANCET=INSTANCET.replace(\" \",\"_\")\n",
        "\n",
        "if Use_Custom_Path:\n",
        "  try:\n",
        "    INSTANCET\n",
        "    del INSTANCET\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "  INSTANCET\n",
        "  if Previous_Session!=\"\":\n",
        "    path_to_trained_model='/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/'+Previous_Session+\"/\"+Previous_Session+'.ckpt'\n",
        "  else:\n",
        "    path_to_trained_model=SESSION_DIR+\"/\"+INSTANCET+'.ckpt'\n",
        "except:\n",
        "  print('\u001b[1;31mIt seems that you did not perform training during this session \u001b[1;32mor you chose to use a custom path,\\nprovide the full path to the model (including the name of the model):\\n')\n",
        "  path_to_trained_model=input()\n",
        "     \n",
        "while not os.path.exists(path_to_trained_model):\n",
        "   print(\"\u001b[1;31mThe model doesn't exist on you Gdrive, use the file explorer to get the path : \")\n",
        "   path_to_trained_model=input()\n",
        "   \n",
        "fgitclone = \"git clone --depth 1\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    if not os.path.exists('/content/gdrive/MyDrive/Fast-Dreambooth'):\n",
        "      !mkdir -p /content/gdrive/MyDrive/Fast-Dreambooth\n",
        "    time.sleep(2)\n",
        "    %mkdir -p /content/gdrive/MyDrive/Fast-Dreambooth/sd_db\n",
        "    %cd /content/gdrive/MyDrive/Fast-Dreambooth/sd_db\n",
        "    !$fgitclone --branch main https://github.com/Stability-AI/stablediffusion\n",
        "    !$fgitclone --branch Colabdb https://github.com/TheLastBen/stable-diffusion-webui\n",
        "    !mkdir -p /content/gdrive/MyDrive/Fast-Dreambooth/sd_db/stable-diffusion-webui/cache/huggingface\n",
        "    !ln -s /content/gdrive/MyDrive/Fast-Dreambooth/sd_db/stable-diffusion-webui/cache/huggingface /root/.cache/\n",
        "    %cd /content/gdrive/MyDrive/Fast-Dreambooth/sd_db/stable-diffusion-webui\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32m')\n",
        "!git pull\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  if not os.path.exists('/content/gdrive/MyDrive/Fast-Dreambooth/sd_db/stablediffusion/src/k-diffusion/k_diffusion'):\n",
        "    !mkdir /content/gdrive/MyDrive/Fast-Dreambooth/sd_db/stablediffusion/src\n",
        "    %cd /content/gdrive/MyDrive/Fast-Dreambooth/sd_db/stablediffusion/src\n",
        "    !$fgitclone https://github.com/TheLastBen/taming-transformers\n",
        "    !$fgitclone https://github.com/salesforce/BLIP blip\n",
        "    !$fgitclone https://github.com/sczhou/CodeFormer codeformer\n",
        "    !$fgitclone --branch master https://github.com/crowsonkb/k-diffusion\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  if not os.path.exists('/tools/node/bin/lt'):\n",
        "    !npm install -g localtunnel\n",
        "\n",
        "Use_localtunnel = False\n",
        "\n",
        "User = \"\"\n",
        "Password= \"\"\n",
        "\n",
        "auth=f\"--gradio-auth {User}:{Password}\"\n",
        "if User ==\"\" or Password==\"\":\n",
        "  auth=\"\"\n",
        "\n",
        "share=''\n",
        "if not Use_localtunnel:\n",
        "  share='--share'\n",
        "  !wget -q -O /usr/local/lib/python3.8/dist-packages/gradio/blocks.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/blocks.py\n",
        "\n",
        "else:\n",
        "  with capture.capture_output() as cap:\n",
        "    share=''\n",
        "    %cd /content\n",
        "    !nohup lt --port 7860 > srv.txt 2>&1 &\n",
        "    time.sleep(2)\n",
        "    !grep -o 'https[^ ]*' /content/srv.txt >srvr.txt\n",
        "    time.sleep(2)\n",
        "    srv= getoutput('cat /content/srvr.txt')\n",
        "\n",
        "    for line in fileinput.input('/usr/local/lib/python3.8/dist-packages/gradio/blocks.py', inplace=True):\n",
        "      if line.strip().startswith('self.server_name ='):\n",
        "          line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
        "      if line.strip().startswith('self.protocol = \"https\"'):\n",
        "          line = '            self.protocol = \"https\"\\n'\n",
        "      if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n",
        "          line = ''\n",
        "      if line.strip().startswith('else \"http\"'):\n",
        "          line = ''\n",
        "      sys.stdout.write(line)\n",
        "\n",
        "    !rm /content/srv.txt\n",
        "    !rm /content/srvr.txt\n",
        "    %cd /content/gdrive/MyDrive/Fast-Dreambooth/sd_db/stable-diffusion-webui\n",
        "\n",
        "if Model_Version == \"V2.1-768\":\n",
        "  configf=\"--config /content/gdrive/MyDrive/Fast-Dreambooth/sd_db/stablediffusion/configs/stable-diffusion/v2-inference-v.yaml\"\n",
        "elif Model_Version == \"V2.1-512\":\n",
        "  configf=\"--config /content/gdrive/MyDrive/Fast-Dreambooth/sd_db/stablediffusion/configs/stable-diffusion/v2-inference.yaml\"\n",
        "else:\n",
        "  configf=\"\"\n",
        "\n",
        "clear_output()\n",
        "\n",
        "if os.path.isfile(path_to_trained_model):\n",
        "  !python /content/gdrive/MyDrive/Fast-Dreambooth/sd_db/stable-diffusion-webui/webui.py $share --ckpt \"$path_to_trained_model\" $configf $auth\n",
        "else:\n",
        "  !python /content/gdrive/MyDrive/Fast-Dreambooth/sd_db/stable-diffusion-webui/webui.py $share --ckpt-dir \"$path_to_trained_model\" $configf $auth"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-HS8M_jBz4mh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "WCgtpGr6ZOyG",
        "bbKbx185zqlz",
        "Wsp71Ctje5qg",
        "rYmyuQctfATh",
        "OmIz45s0gH5c",
        "Qbclw_Gmg3DC"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}